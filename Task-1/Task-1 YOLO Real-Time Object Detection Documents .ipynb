{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab00cad6",
   "metadata": {},
   "source": [
    "#               You Only Look Once: Unified, Real-Time Object Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55ffc3",
   "metadata": {},
   "source": [
    "## Overview: <hr>\n",
    "   In this paper, we introduce YOLO, a novel approach to object detection that differs from previous methods by reframing the task as a regression problem for spatially separated bounding boxes and class probabilities. Unlike traditional approaches that repurpose classifiers for detection, YOLO utilizes a single neural network to predict bounding boxes and class probabilities directly from full images in a single evaluation. This unified architecture allows for end-to-end optimization, resulting in highly efficient performance. Our base YOLO model achieves real-time processing of images at 45 frames per second, while a smaller variant, Fast YOLO, achieves an impressive 155 frames per second while maintaining double the mean Average Precision (mAP) of other real-time detectors. Although YOLO may exhibit more localization errors compared to state-of-the-art systems, it demonstrates reduced false positive predictions on background. Furthermore, YOLO exhibits strong generalization capabilities, outperforming alternative detection methods such as DPM and R-CNN when applied to diverse domains, including artwork."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26c806",
   "metadata": {},
   "source": [
    "## Content: <hr>\n",
    "1. Introduction <br>\n",
    "2. Unified Detection  <br>\n",
    "3. Comparison to Other Detection Systems <br>\n",
    "4. Experiments <br>\n",
    "5. Real-Time Detection In The Wild <br>\n",
    "6. Conclusion <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a2d48",
   "metadata": {},
   "source": [
    "## 1. Introduction <hr>\n",
    "Human beings possess an extraordinary capability to swiftly process visual information, recognizing objects, their spatial arrangements, and interactions with remarkable speed and accuracy. This innate proficiency underpins various activities, from navigating complex environments to interpreting dynamic scenes. In the realm of artificial intelligence and computer vision, achieving comparable levels of efficiency and accuracy in object detection has been a longstanding pursuit. Current detection systems often rely on repurposing classifiers, leveraging techniques such as sliding window approaches or region proposal methods to identify objects within images. However, recent developments in object detection algorithms have shown promising advancements, moving closer towards mimicking the rapid and precise capabilities of the human visual system. This paper delves into the evolution of object detection methodologies, examining the transition from conventional approaches to more sophisticated techniques inspired by human perception. <br>\n",
    "* You Only Look Once (YOLO) is a viral and widely used algorithm [1]. YOLO is famous for its object \n",
    "detection characteristic. In 2015, Redmon et al. gave the introduction of the first YOLO version [2]. In the past \n",
    "years, scholars have published several YOLO subsequent versions described as YOLO V2, YOLO V3, YOLO \n",
    "V4, and YOLO V5 [3-10]. There are a few revised-limited versions, such as YOLO-LITE [11-12]. This research \n",
    "paper only focused on the five main YOLO versions. \n",
    "* This paper will compare the main differences among the five YOLO versions from both conceptual designs \n",
    "and implementations. The YOLO versions are improving, and it is essential to understand the main motivations, \n",
    "features development, limitations, and even relationships for the versions. This reviewing paper will be \n",
    "meaningful and insightful for object detection researchers, especially for beginners. \n",
    "*The following first section will give a version comparing from the technique perspective along with the version \n",
    "similarities. The second section describes them through public data. The insightful results are displayed using \n",
    "both figures and tabular. The two primary analyses are focused on the YOLO trends and YOLO-related queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14638eca",
   "metadata": {},
   "source": [
    "## 2. Unified Detection <hr>\n",
    "The YOLO (You Only Look Once) algorithm revolutionizes the field of object detection by consolidating various components into a single neural network. Unlike traditional methods that involve multiple stages of processing, YOLO considers the entire image at once, leveraging global features to predict bounding boxes and class probabilities for all objects simultaneously. This holistic approach enables the model to reason globally about the image, enhancing its accuracy in detecting objects of varying sizes and complexities.\n",
    "One of the key advantages of YOLO is its ability to maintain real-time speeds while ensuring high average precision. By dividing the input image into a grid structure, YOLO assigns responsibility to individual grid cells for detecting objects whose centers lie within them. Each grid cell predicts multiple bounding boxes along with confidence scores, indicating both the presence of an object and the accuracy of the predicted box. This confidence score is determined by the product of the probability of an object being present (Pr(Object)) and the Intersection over Union (IOU) between the predicted box and the ground truth. <br>\n",
    "The predictions made by YOLO comprise five parameters: the coordinates of the bounding box center (x, y), its width (w), height (h), and the confidence score. These predictions are made relative to the grid cell and the entire image, providing flexibility in capturing object positions and sizes accurately. Additionally, YOLO predicts conditional class probabilities for each grid cell, irrespective of the number of bounding boxes predicted. These probabilities represent the likelihood of each class being present in the detected object within the grid cell. <br>\n",
    "<img src=\"Photo/yolo-cnn.webp\" alt=\"Italian Trulli\">\n",
    "During inference, YOLO calculates class-specific confidence scores for each predicted box by combining conditional class probabilities and individual box confidence predictions. This calculation yields scores that encode both the probability of a particular class appearing in the box and how well the predicted box aligns with the actual object. Overall, YOLO's unified approach, grid-based methodology, and efficient inference mechanism make it a versatile and powerful solution for various object detection tasks, ranging from autonomous driving to surveillance systems.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0885b",
   "metadata": {},
   "source": [
    "## 3. Comparison to Other Detection Systems: <hr>\n",
    "<img src=\"Photo/Images.png\" alt=\"Italian Trulli\">\n",
    "\n",
    "**Traditional Detection Pipelines:**<br>\n",
    "Detection pipelines traditionally involve extracting robust features from images using methods like Haar, SIFT, HOG, or convolutional features, followed by classification or localization using classifiers or localizers. <br>\n",
    "**Comparison with YOLO:**<br>\n",
    "The document compares YOLO with various detection frameworks, highlighting its advantages in terms of speed, accuracy, and simplicity compared to methods like Deformable Parts Models (DPM), R-CNN, and others.<br>\n",
    "**Unified Architecture of YOLO**:<br>\n",
    "YOLO employs a unified architecture where a single convolutional neural network handles feature extraction, bounding box prediction, non-maximal suppression, and contextual reasoning concurrently. This unified approach leads to faster and more accurate detection compared to disjoint pipelines.<br>\n",
    "**Comparison with R-CNN:**<br>\n",
    "YOLO shares similarities with R-CNN, such as proposing bounding boxes and scoring them using convolutional features. However, YOLO imposes spatial constraints on grid cell proposals to mitigate duplicate detections and proposes fewer bounding boxes, leading to improved efficiency.<br>\n",
    "**Speed Improvements Over Traditional Methods:**<br>\n",
    "YOLO and other fast detectors improve upon traditional methods by leveraging neural networks for region proposal and feature extraction, resulting in significant speed improvements while maintaining or enhancing accuracy.<br>\n",
    "**General-purpose Detector:**<br>\n",
    "Unlike detectors optimized for single classes like faces or people, YOLO is a general-purpose detector capable of detecting a variety of objects simultaneously, making it versatile for various applications.<br>\n",
    "**Comparison with MultiBox and OverFeat:**<br>\n",
    "YOLO is compared to MultiBox and OverFeat, highlighting its distinction as a complete detection system capable of general object detection, whereas MultiBox and OverFeat are still parts of larger detection pipelines.<br>\n",
    "**Global Context Reasoning:**<br>\n",
    "The document emphasizes YOLO's ability to reason about global context during detection, contrasting with methods like OverFeat, which only consider local information and require significant post-processing for coherent detections.<br>\n",
    "**Versatility and Complexity:**<br>\n",
    "YOLO's versatility lies in its ability to handle complex detection tasks without the need for extensive post-processing or tuning of individual pipeline components.<br>\n",
    "\n",
    "## Yolo Architecture Diagram:\n",
    "<img src=\"Photo/spp.jpeg\" alt=\"Italian Trulli\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302a4aa9",
   "metadata": {},
   "source": [
    "## 4) Experiments: <hr>\n",
    "It seems like you're presenting an excerpt from a paper discussing the comparison between YOLO (You Only Look Once) and other real-time object detection systems on the PASCAL VOC 2007 dataset. Here's a breakdown and interpretation of the key points mentioned in the excerpt:\n",
    "\n",
    "Comparison with Other Real-Time Systems: The paper compares YOLO with other real-time object detection systems, particularly focusing on its performance against Fast R-CNN, one of the high-performing variants of R-CNN. The comparison includes examining error profiles on the VOC 2007 dataset to understand the differences between YOLO and Fast R-CNN.\n",
    "\n",
    "Rescoring Fast R-CNN Detections: It suggests that YOLO can be used to rescore Fast R-CNN detections, potentially reducing errors from background false positives and providing a significant performance boost. This indicates that YOLO may complement or enhance the performance of existing detection systems like Fast R-CNN.\n",
    "\n",
    "Results on VOC 2012 Dataset: The paper also presents results on the VOC 2012 dataset and compares the mean Average Precision (mAP) with current state-of-the-art methods. This provides insights into the generalization and performance of YOLO across different datasets and scenarios.\n",
    "\n",
    "Generalization to New Domains: The excerpt mentions that YOLO generalizes well to new domains, particularly in comparison to other detectors, on two artwork datasets. This suggests that YOLO's effectiveness extends beyond specific datasets or domains.\n",
    "\n",
    "Speed and Accuracy Tradeoffs: The comparison considers both speed and accuracy tradeoffs among different object detection systems. It highlights YOLO's real-time performance while maintaining competitive accuracy, making it a favorable choice for applications requiring speed and efficiency.\n",
    "\n",
    "Models and Implementations: The paper mentions different variations of YOLO, including Fast YOLO and YOLO trained using VGG-16, each with varying tradeoffs between speed and accuracy. It also discusses other systems like Fastest DPM (Deformable Parts Model) and R-CNN minus R, providing a comprehensive comparison across different methodologies. <Br>\n",
    "<img src=\"Photo/map50blue.png\" alt=\"Italian Trulli\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2c63d",
   "metadata": {},
   "source": [
    "## 5. Real-Time Detection In The Wild: <hr>\n",
    "\"YOLO's real-time object detection capabilities represent a significant advancement in computer vision, offering both speed and accuracy crucial for various applications. By seamlessly integrating YOLO with a webcam, we conducted rigorous tests to validate its real-time performance in detecting objects 'in the wild.' This entails processing live video streams from the webcam, ensuring that YOLO can swiftly analyze each frame and accurately identify objects within the scene. Such real-world verification underscores YOLO's applicability across diverse domains, including video surveillance, autonomous navigation, robotics, and augmented reality. Its ability to maintain high performance amidst dynamic environmental factors reaffirms YOLO's position as a versatile and dependable solution for real-time object detection tasks.\"\n",
    "<img src=\"Photo/Screenshot 2024-02-26 091452.png\" alt=\"Italian Trulli\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0234d",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "This paper gives us a review of the YOLO versions. Here we draw the following remarks. First, the YOLO \n",
    "version has a lot of differences. However, they still have some features in common. Hence, they are still similar. \n",
    "Second. The YOLO versions are still very new, have a lot of room for future research. Especially for scenario \n",
    "implementations. <br> \n",
    "My opinion There is still room for future improvement. This paper can focus more on the implementations comparing, \n",
    "such as scenario analysis. Further, the research for YOLO V1 is very limited in this paper. For example, in the \n",
    "trend subsection, both the figure and tabular have ignored YOLO V1. Future research can do better on this point.\n",
    "The YOLO model has significantly advanced the field of object detection, offering a real-time solution with impressive accuracy. With the latest version, YOLOv5, the model achieves exceptional performance, even on low-resource devices. As researchers and engineers continue to improve the YOLO architecture, we can expect further advancements in object detection capabilities, catering to a wide range of practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50367d5",
   "metadata": {},
   "source": [
    "## References:\n",
    "You Only Look Once:\n",
    "Unified, Real-Time Object Detection\n",
    "Joseph Redmon∗, Santosh Divvala∗†, Ross Girshick¶, Ali Farhadi∗†University of Washington∗, Allen Institute for AI†, Facebook AI Research¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979db12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
